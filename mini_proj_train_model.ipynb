{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Here you will load the images, create a model and train it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the dataset directory and the ordered list of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '.\\dataset'\n",
    "class_names = ['left','straight','right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to preprocess each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    scale_percent = 40 # percent of original size\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in each image in the dataset directory, run the preprocessing and then them into a list called `data`. Create a corresponding list of the assigned labels called `data_labels`.  Then at the end, convert the lists to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./dataset\\left\\._00138_0.54.jpg\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5464\\3255867957.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mpreprocessed_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mdata_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5464\\450274004.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mscale_percent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m \u001b[1;31m# percent of original size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data_labels = []\n",
    "\n",
    "for class_idx,class_name in enumerate(class_names):\n",
    "    dir_name = os.path.join(dataset_dir,class_name)\n",
    "    for file in os.listdir(dir_name):\n",
    "        if (file.endswith('.png') or file.endswith('.jpg')):\n",
    "            full_path = os.path.join(dir_name,file)\n",
    "            print(full_path)\n",
    "            image = cv2.imread(full_path)\n",
    "            preprocessed_image = preprocess(image)\n",
    "            data.append(preprocessed_image)\n",
    "            data_labels.append(class_idx)\n",
    "\n",
    "data = np.array(data)\n",
    "data_labels = np.array(data_labels)\n",
    "\n",
    "\n",
    "\n",
    "#--------------- Mirror functionality written by lucanatorvs -------------------------------------------------------------\n",
    "\n",
    "# we mirror the data to increase the dataset, every image is flipped horizontally, and the label is changed accordingly; left becomes right, right becomes left and straight stays straight\n",
    "\n",
    "data_mirror = np.flip(data,2)\n",
    "data_mirror_labels = np.copy(data_labels)\n",
    "data_mirror_labels[data_mirror_labels == 0] = 3\n",
    "data_mirror_labels[data_mirror_labels == 2] = 0\n",
    "data_mirror_labels[data_mirror_labels == 3] = 2\n",
    "\n",
    "# now we concatenate the original data and the mirrored data to get a bigger dataset\n",
    "data = np.concatenate((data,data_mirror),axis=0)\n",
    "data_labels = np.concatenate((data_labels,data_mirror_labels),axis=0)\n",
    "\n",
    "# now crop the top 20 pixels from the image, to remove the sky and the horizon\n",
    "data = data[:,25:,:]\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "print(data.shape)\n",
    "print(data_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the images to make sure everything went okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "columns = 2\n",
    "fig, axes = plt.subplots(rows,columns,figsize=(6,6))\n",
    "for i,ax in enumerate(axes.ravel()):\n",
    "    idx = random.choice(range(data.shape[0]))\n",
    "    ax.imshow(data[idx],cmap='gray')\n",
    "    ax.set_title(class_names[data_labels[idx]])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset dimesions to see how many instances and labels there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape:\",data.shape)\n",
    "print(\"Labels shape:\", data_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting / Model Definition / Training / Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you have succefully prepared your images for training.  Now you have to split this data into training validation, and test sets, then create a suitable model, train it and then test it, and finally if you are satisfied with your performance you can save the model. The saved model can be later loaded in your Jetracer for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Written by lucanatorvs --------------------------------------------------------------\n",
    "# first we make a test set, and then we split the remaining data into a validation and a training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, data_labels, test_size=0.2, random_state=69)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=69)\n",
    "\n",
    "# now we print the shape of the data\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape:', X_val.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------- Model is WIP, should be changed to CNN -------------------------------------------------------\n",
    "\n",
    "model = Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(64, 89, 3)),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu',kernel_regularizer=regularizers.l2(l=0.01)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu',kernel_regularizer=regularizers.l2(l=0.01)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu',kernel_regularizer=regularizers.l2(l=0.01)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(128, 3, padding='same', activation='relu',kernel_regularizer=regularizers.l2(l=0.01)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.1),\n",
    "    layers.Dense(3)\n",
    "])\n",
    "\n",
    "# return the constructed network architecture\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "trained = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_val, y_val))\n",
    "df = pd.DataFrame(trained.history)\n",
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a TensorFlow Lite Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an appropriate output file name for your `.tflite` file.  It may help to use version numbers, and keep track of versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = './mini_FINAL.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert your model (in the variable `model`) and save the `.tflite` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_fp16_model = converter.convert()\n",
    "\n",
    "# This will save your model with the a file name tflite_model_fp16_file.tflite. You can uplaod this model file\n",
    "# in your JetRacer a\n",
    "\n",
    "with open(output_filename, 'wb') as f:\n",
    "    f.write(tflite_fp16_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aai_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f4f7ca94ca24eef438867125c0906f4b1d03d70d8860589503050797217fc288"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
